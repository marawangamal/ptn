# Experiment 1
# Evaluating efficacy of multi-token regularization during pretraining and finetuning
preambles:
  glong:   
    - "#!/bin/bash"
    - "#SBATCH --output=slurm/slurm-%j.out"
    - "#SBATCH --error=slurm/slurm-%j.err"   
    - "#SBATCH --partition=long"
    - "#SBATCH --gres=gpu:rtx8000:1"
    - "#SBATCH --mem=32G"
    - "#SBATCH --cpus-per-task=8"
    - "#SBATCH --nodes=1"
    - "source /home/mila/m/marawan.gamal/scratch/ctn/.venv/bin/activate"


  clong:   
    - "#!/bin/bash"
    - "#SBATCH --output=slurm/slurm-%j.out"
    - "#SBATCH --error=slurm/slurm-%j.err"   
    - "#SBATCH --partition=long"
    - "#SBATCH --mem=32G"
    - "#SBATCH --cpus-per-task=8"
    - "#SBATCH --nodes=1"
    - "source /home/mila/m/marawan.gamal/scratch/ctn/.venv/bin/activate"

group:
  name: "main"
  type: parallel
  jobs:

    - group:
        name: "ucla::mps"
        type: sweep
        preamble: glong
        sweep:
          lr: [5e-3]
          rank: [32]
          model: ["mps"]
          sf: [1]
          dataset: [
              # "nltcs",
              # "msnbc",
              # "kdd",
              # "plants",
              # "baudio",
              # "jester",
              # "bnetflix",
              # "accidents",
              # "mushrooms",
              # "adult",
              # "connect4",
              # "ocr_letters",
              # "rcv1",
              # "tretail",
              # "pumsb_star",
              # "dna",
              # "kosarek",
              "msweb",
              # "nips",
              # "book",
              # "tmovie",
              # "cwebkb",
              # "cr52",
              "c20ng",
              # "moviereview",
              # "bbc",
              # "voting",
              # "ad",
              # "binarized_mnist",
      
          ]
        sweep_template: "python scripts/train_ucla.py --lr {lr} --rank {rank} --model {model} --dataset {dataset} --sf {sf} --epochs 50 --tags scale_factor v2"


    # - group:
    #     name: "ucla::mps::sf0"
    #     type: parallel
    #     jobs:
    #       - job:
    #           preamble: glong
    #           command: "python scripts/train_ucla.py --lr 5e-3 --rank 32 --model mps --dataset nltcs --sf 0 --epochs 50 --tags scale_factors v2"
              