{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd9bb5d0",
   "metadata": {},
   "source": [
    "## Compressed sensing with QFT\n",
    "\n",
    "**Compressed sensing objective**\n",
    "\n",
    "Given a high dimensional signal $\\mathbf{x} \\in\\mathbb{R}^{D}$ we want to find a vector $\\mathbf{s}^*$ in the set. \n",
    "\n",
    "$$\n",
    "\\argmin_{\\mathbf{s} \\in \\mathbb{R}^{D}}  \\|\\mathbf{s}\\|_1  \\\\\n",
    "\\text{s.t. } C\\mathbf{x} = CF^{-1}\\mathbf{s}\n",
    "$$\n",
    "\n",
    "\n",
    "**Tensorized extension of compressed sensing**\n",
    "\n",
    "Given a high dimensional signal $\\mathcal{x} \\in\\mathbb{R}^{D\\times\\cdots\\times D}$ represneted in TT format with ranks $\\{R_i\\}_{i=1}^N$ we want to find a TT-vector $\\mathbf{s}^*$ in the set. \n",
    "\n",
    "$$\n",
    "\\argmin_{\\mathcal{s} \\in \\mathbb{R}^{D}}  \\|\\mathcal{s}\\|_1  \\\\\n",
    "\\text{s.t. } \\mathcal{C}\\mathcal{x} = \\mathcal{C}\\mathcal{F}^{-1}\\mathcal{s}\n",
    "$$\n",
    "\n",
    "where $\\mathcal{C}\\,\\&\\,\\mathcal{F}$ are Matrix Product Operators (MPO).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ffbef851",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import tntorch as tn\n",
    "\n",
    "# Hyperparameters\n",
    "L, R, D = 8, 8, 2\n",
    "\n",
    "dims = (D,)*L\n",
    "s = tn.randn(*dims, ranks_tt=R, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bab1de11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install quimb\n",
    "import quimb as qu\n",
    "import quimb.tensor as qtn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bbe2b75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s\n",
      " 8 8 8 8 8 8 8 \n",
      "●─●─●─●─●─●─●─●\n",
      "│ │ │ │ │ │ │ │\n",
      "None\n",
      "\n",
      "w_mpo\n",
      "│8│8│8│8│8│8│8│\n",
      "●─●─●─●─●─●─●─●\n",
      "│ │ │ │ │ │ │ │\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "s_mps = qtn.MPS_rand_state(L=L, bond_dim=R, tags=['S'])  # sparse tensor\n",
    "\n",
    "# This will be the combined inverse fourier MPO + sampler MPO\n",
    "w_mpo = qtn.MPO_rand_herm(L=L, bond_dim=R, tags=['HAM'])  \n",
    "\n",
    "# Target we want to reconstruct\n",
    "x_targ_mps = qtn.MPS_rand_state(L=L, bond_dim=R, tags=['X'])  # dense tensor\n",
    "\n",
    "print(\"s\")\n",
    "print(s_mps.show())\n",
    "\n",
    "print(\"\\nw_mpo\")\n",
    "print(w_mpo.show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3b56e9c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.001614892659119"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def loss_fn(s_mps, w_mpo, x_targ_mps):\n",
    "    x_hat_mps = w_mpo.apply(other=s_mps)\n",
    "    psi = x_hat_mps - x_targ_mps\n",
    "    return psi.norm()\n",
    "\n",
    "loss_fn(s_mps, w_mpo, x_targ_mps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7de1f145",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TNOptimizer(d=800, backend=torch)>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tnopt = qtn.TNOptimizer(\n",
    "    # the tensor network we want to optimize\n",
    "    s_mps,\n",
    "    # the functions specfying the loss and normalization\n",
    "    loss_fn=loss_fn,\n",
    "    # norm_fn=norm_fn,\n",
    "    # we specify constants so that the arguments can be converted\n",
    "    # to the  desired autodiff backend automatically\n",
    "    loss_constants={\"w_mpo\": w_mpo, \"x_targ_mps\": x_targ_mps},\n",
    "    # the underlying algorithm to use for the optimization\n",
    "    # 'l-bfgs-b' is the default and often good for fast initial progress\n",
    "    optimizer=\"adam\",\n",
    "    # which gradient computation backend to use\n",
    "    autodiff_backend=\"torch\",\n",
    ")\n",
    "tnopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "255024cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "+0.305455653889 [best: +0.305455653889] : : 1001it [00:03, 266.70it/s]                        \n"
     ]
    }
   ],
   "source": [
    "s_mps_opt = tnopt.optimize(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e6a6d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
