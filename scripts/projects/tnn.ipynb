{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3549bd2",
   "metadata": {},
   "source": [
    "## Tensorized Neural Networks (TNN)\n",
    "\n",
    "Computes $f_n \\circ \\cdots \\circ f_0 (x)$, where $x$ is an MPS tensor and each $f_i$ is an MPO followed by a rank dropout and non-linearity \n",
    "\n",
    "Next steps:\n",
    "- Add regression and classification heads\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4df6d3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Union, Optional\n",
    "import torch\n",
    "\n",
    "def mpo_contract(\n",
    "    mpo: Union[List[torch.Tensor], torch.nn.ParameterList], \n",
    "    mps: Union[List[torch.Tensor], torch.Tensor]\n",
    "    ) -> Union[List[torch.Tensor], torch.Tensor]: # returns a new mps\n",
    "    \"\"\"Perform a tensor network contraction of an MPO and an MPS. Returns a new MPS.\n",
    "\n",
    "    Args:\n",
    "        mpo (List[torch.Tensor]): A list of tensors representing the MPO. Shape: (Rl, Di, Do, Rr)\n",
    "        mps (List[torch.Tensor]): A list of tensors representing the MPS. Shape: (B, Rl, Di, Rr)\n",
    "\n",
    "    Returns:\n",
    "        List[torch.Tensor]: A list of tensors representing the new MPS. Shape: (B, Do, Rl, Rr)\n",
    "    \"\"\"\n",
    "    out = []\n",
    "    for i in range(len(mpo)):\n",
    "        mps_prime = torch.einsum('rios,bpiq->brposq', mps[i], mpo[i])\n",
    "        B, R, P, Do, S, Q = mps_prime.shape\n",
    "        out.append(mps_prime.reshape(B, R*P, Do, S*Q))\n",
    "    return out\n",
    "\n",
    "\n",
    "class MPO(torch.nn.Module):\n",
    "    def __init__(self, in_features: List[int], out_features: List[int], ranks: List[int], max_rank: int = 2):\n",
    "        super(MPO, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.ranks = ranks\n",
    "        self.max_rank = max_rank\n",
    "        self.g = torch.nn.ParameterList([\n",
    "            torch.nn.Parameter(torch.randn(ranks[i], in_features[i], out_features[i], ranks[i+1]))\n",
    "            for i in range(len(in_features))  # (Rk, Ik, Ok, Rk+1)\n",
    "        ])\n",
    "\n",
    "    def forward(self, mps_x: List[torch.Tensor], mps_y: Optional[List[torch.Tensor]] = None) -> torch.Tensor:\n",
    "        # mps_x:[(B, Rl, Di, Rr), ...], mps_y:[(B, Rl, Do, Rr), ...]\n",
    "\n",
    "        # MPO x MPS\n",
    "        mps_y_hat = mpo_contract(self.g, mps_x)  \n",
    "\n",
    "        # Rank dropout\n",
    "        mps_y_hat_reduced = []\n",
    "        for i in range(len(mps_y_hat)):\n",
    "            # print(mps_y_hat[i].shape, self.max_rank)\n",
    "            Rl = torch.randint(0, mps_y_hat[i].shape[1], (self.max_rank,))  # (B, Rl, Do, Rr)\n",
    "            Rr = torch.randint(0, mps_y_hat[i].shape[3], (self.max_rank,))\n",
    "            # print(Rl, Rr)\n",
    "            mps_y_hat_reduced.append(mps_y_hat[i][:, Rl][:, :, :, Rr])\n",
    "\n",
    "        # Non-linearity\n",
    "        mps_y_hat_reduced = [torch.relu(mps_y_hat_reduced[i]) for i in range(len(mps_y_hat_reduced))]\n",
    "        \n",
    "        return mps_y_hat_reduced\n",
    "\n",
    "class TNN(torch.nn.Module):\n",
    "    def __init__(self, in_features: List[int], out_features: List[int], n_layers: int=4, max_rank: int = 2):\n",
    "        super(TNN, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.n_layers = n_layers\n",
    "        self.max_rank = max_rank\n",
    "        self.layers = torch.nn.ModuleList([\n",
    "            MPO(\n",
    "                in_features=in_features, \n",
    "                out_features=out_features, \n",
    "                ranks=[2] * (n_layers + 1), \n",
    "                max_rank=max_rank\n",
    "            ) for _ in range(n_layers)\n",
    "        ])\n",
    "    \n",
    "    def forward(self, mps_x: List[torch.Tensor], mps_y: Optional[List[torch.Tensor]] = None) -> torch.Tensor:\n",
    "        for i, layer in enumerate(self.layers):\n",
    "            mps_x = layer(mps_x, mps_y)\n",
    "        return mps_x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8667c2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPSx cores: torch.Size([2, 2, 2, 2]), torch.Size([2, 2, 2, 2])\n",
      "MPSy cores: torch.Size([2, 2, 2, 2]), torch.Size([2, 2, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------------------------------------\n",
    "# Test TNN (Uses 8 MPO layers w/ non-linearities\n",
    "# ----------------------------------------------------------\n",
    "\n",
    "# Hyperparameters\n",
    "batch_size, n_layers, max_rank, = 2, 8, 2\n",
    "in_features, out_features, ranks = [2, 2], [2, 2], [2, 2, 2]\n",
    "\n",
    "# Init model\n",
    "mps_x = [torch.randn(batch_size, ranks[i], in_features[i], ranks[i+1]) for i in range(len(in_features))]\n",
    "ttn = TNN(in_features=in_features, out_features=out_features, n_layers=n_layers, max_rank=max_rank)\n",
    "\n",
    "# Forward pass\n",
    "mps_y = ttn(mps_x)\n",
    "print(f\"MPSx cores: \" + ', '.join([str(m.shape) for m in mps_x]))\n",
    "print(f\"MPSy cores: \" + ', '.join([str(m.shape) for m in mps_y]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad2ec40",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
