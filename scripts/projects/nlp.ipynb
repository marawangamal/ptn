{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9357ae63",
   "metadata": {},
   "source": [
    "## NLP with MPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "79a13ba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size before training: 0\n",
      "\n",
      "\n",
      "\n",
      "Vocab size after training: 1024\n"
     ]
    }
   ],
   "source": [
    "from tokenizers import Tokenizer, models, trainers, pre_tokenizers, normalizers\n",
    "\n",
    "# Initialize\n",
    "tokenizer = Tokenizer(models.BPE())\n",
    "tokenizer.normalizer = normalizers.NFKC()\n",
    "tokenizer.pre_tokenizer = pre_tokenizers.Whitespace()\n",
    "\n",
    "# Setup trainer\n",
    "trainer = trainers.BpeTrainer(\n",
    "    vocab_size=2**10,\n",
    "    special_tokens=[\"<pad>\", \"<unk>\", \"<s>\", \"</s>\"]\n",
    ")\n",
    "\n",
    "# Check file exists\n",
    "import os\n",
    "corpus_path = \"../../data/shakespeare/main.txt\"\n",
    "assert os.path.exists(corpus_path), f\"File not found: {corpus_path}\"\n",
    "\n",
    "# Train\n",
    "print(\"Vocab size before training:\", tokenizer.get_vocab_size())\n",
    "tokenizer.train([corpus_path], trainer)\n",
    "\n",
    "# Save and verify\n",
    "tokenizer.save(\"bpe_tokenizer.json\")\n",
    "print(\"Vocab size after training:\", tokenizer.get_vocab_size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "682ce1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "import torch\n",
    "\n",
    "def dec2bin(x, bits):\n",
    "    # mask = 2 ** torch.arange(bits).to(x.device, x.dtype)\n",
    "    mask = 2 ** torch.arange(bits - 1, -1, -1).to(x.device, x.dtype)\n",
    "    return x.unsqueeze(-1).bitwise_and(mask).ne(0).float()\n",
    "\n",
    "\n",
    "def bin2dec(b, bits):\n",
    "    mask = 2 ** torch.arange(bits - 1, -1, -1).to(b.device, b.dtype)\n",
    "    return torch.sum(mask * b, -1)\n",
    "\n",
    "# # Example\n",
    "# NUM_BITS_PER_TOKEN = 10\n",
    "# d = torch.randint(0, 16, (3, 6))\n",
    "# b = dec2bin(d, NUM_BITS_PER_TOKEN)\n",
    "# d_rec = bin2dec(b, NUM_BITS_PER_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "9383bd33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config.vocab_size: 1024\n",
      "word_size: 10.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/31803 [00:04<37:08:47,  4.20s/it, loss=0.695]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Step 0/31803 | Loss: 0.6953\n",
      "Sample: earth whom pp row ST leave war ING dra d PET B brother cond IOLAN sha f ght S q d should ven prince than i cut 3 pardon uty ither hich\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 51/31803 [00:20<12:54:16,  1.46s/it, loss=0.693]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Step 50/31803 | Loss: 0.6931\n",
      "Sample: B M ight ONTES crown What BRO cl RAN llow meet wr : orn ber CL ed ers irst ken fi It orn will da ta ase conf bus young g re\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 101/31803 [00:36<12:39:53,  1.44s/it, loss=0.691]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Step 100/31803 | Loss: 0.6909\n",
      "Sample: gone little ay fort ere vi w EDW ex UCES ace ure uke down LEONTES hence say ation ure did sen H young ca pr In con GR their IV why last\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 151/31803 [00:52<12:20:59,  1.40s/it, loss=0.688]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Step 150/31803 | Loss: 0.6885\n",
      "Sample: no e ad ' une like But ed It You sc What up fall up ISAB Shall upon then a b Lord s pr still honour for thou - ES DU thy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 201/31803 [01:09<12:39:45,  1.44s/it, loss=0.686]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Step 200/31803 | Loss: 0.6863\n",
      "Sample: mer IZ qui UM man good thine g ce sub reat pp be r fal jo Nay hi N news pro I am by York qu ven KE all WARWICK did ARD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 251/31803 [01:26<12:56:44,  1.48s/it, loss=0.685]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Step 250/31803 | Loss: 0.6851\n",
      "Sample: lit The VI rep WARWIC z gr ? Here when ISABELLA by A ' ass , ow from name ng -- IUS when vo tle set ose what ck Th da that\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 301/31803 [01:42<13:07:24,  1.50s/it, loss=0.684]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Step 300/31803 | Loss: 0.6839\n",
      "Sample: ENCE rep tong ord IOLAN e LADY YOR vy of ad st ath LUCIO are ment it sa ep EDWARD entle ON Than dr ction f V may ur ic ouse tain\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 351/31803 [01:59<12:56:01,  1.48s/it, loss=0.681]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Step 350/31803 | Loss: 0.6811\n",
      "Sample: af , bre der WARWIC M try x : some happ she hast kes A st $ el iness na ven a LADY morrow ! sha ve gra bear As be ver\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 401/31803 [02:16<12:53:54,  1.48s/it, loss=0.681]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Step 400/31803 | Loss: 0.6805\n",
      "Sample: ere king come est IET she : ces ,-- . rom CAL itizen ins Citizen Yet off 3 O GR clo you hear shi pla lo II age D off wor tra\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 451/31803 [02:32<12:40:39,  1.46s/it, loss=0.678]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Step 450/31803 | Loss: 0.6779\n",
      "Sample: die true ake ves CORIOLANUS noble tre ck ook What house their cious fl and B INC upon lo ent To much when n ust ite : ans um the und need\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 501/31803 [02:49<12:58:24,  1.49s/it, loss=0.677]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Step 500/31803 | Loss: 0.6771\n",
      "Sample: eng hour The ur sel st den BRUTUS pt ive EL CORIOLAN KING There our tr shame la EN mo ey out would fa c ven ABETH . ght UTUS q K\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 551/31803 [03:06<13:14:28,  1.53s/it, loss=0.676]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Step 550/31803 | Loss: 0.6756\n",
      "Sample: kes ry he nd sweet life to MEN IUS thee ti is bear cannot GLOUCESTER why master : come KE grace of bo shall self Thou brother RAN M by an\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 601/31803 [03:23<12:48:15,  1.48s/it, loss=0.673]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Step 600/31803 | Loss: 0.6734\n",
      "Sample: Q ser t SIC UT ds A any ces SICINIUS ? can h G HAM EDW c et QUEEN wi ting under reat ast gr ca thought q know fore ? cl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 651/31803 [03:39<12:29:44,  1.44s/it, loss=0.673]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Step 650/31803 | Loss: 0.6733\n",
      "Sample: LUC H able : mother p which true ull how on qui par MENENIUS vant ve ure Q sha BR ady e sir swe K 3 DW E men D GRE shall\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 701/31803 [03:55<12:39:10,  1.46s/it, loss=0.671]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Step 700/31803 | Loss: 0.6714\n",
      "Sample: thought wr ri ig come th fa or ? pri hear look ess nd sha ere cha ing th R ARD For his ass BRO He ou hi dis Than gue k\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 751/31803 [04:11<12:25:21,  1.44s/it, loss=0.669]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Step 750/31803 | Loss: 0.6690\n",
      "Sample: all ve um never mother CA come ace shall ate ul pardon Lord w J hold ra Nor Nay land in n is lady m , young f wer hath ME\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 801/31803 [04:27<12:22:57,  1.44s/it, loss=0.668]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Step 800/31803 | Loss: 0.6677\n",
      "Sample: when KING hi sor uke ter s by D sp ook is ly ep ther shall B and row great : H tongue they heaven By ome selves V - &\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 851/31803 [04:43<12:33:11,  1.46s/it, loss=0.667]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Step 850/31803 | Loss: 0.6671\n",
      "Sample: maid & IN P grace ou qu Have TES um Nor M ETH ang sc f No N , as iz $ were bear ay an on me Z and\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 901/31803 [05:00<12:56:44,  1.51s/it, loss=0.67] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Step 900/31803 | Loss: 0.6695\n",
      "Sample: ill have ght Henry PETRUCH ARD There P hat char - llow the A de mother before OR can own ward se y sa am o ook y pray or tain ord\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 951/31803 [05:16<12:25:56,  1.45s/it, loss=0.663]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Step 950/31803 | Loss: 0.6628\n",
      "Sample: ar ENCE R S whi ans f d at X r de su er atch ap ll o some n J d SICINIUS EDW of should therefore N grace head A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1001/31803 [05:32<12:28:20,  1.46s/it, loss=0.661]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Step 1000/31803 | Loss: 0.6615\n",
      "Sample: house ? oo ing dy in N th B can far with ti TES And ser - I are ong his ing or . God it de hand A A jo ry\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1051/31803 [05:49<12:35:25,  1.47s/it, loss=0.662]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Step 1050/31803 | Loss: 0.6616\n",
      "Sample: lt you with int uke DUKE bed ould Here nd pl st ish their L N am , uch say sp ere sha ow and se W E ight U art\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1101/31803 [06:06<12:41:47,  1.49s/it, loss=0.663]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Step 1100/31803 | Loss: 0.6625\n",
      "Sample: fear re E fi z 3 w N , P PETRUCHIO my K A rom We int al Q mother The m s ! ed um ant K set hi law\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 1151/31803 [06:22<12:18:33,  1.45s/it, loss=0.659]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Step 1150/31803 | Loss: 0.6591\n",
      "Sample: ou come ELIZ V man K , ; self EDWARD Not hand IUS Th lord pe himself K RICH ter str or pr wor head ce ' their se ess ive S\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 1201/31803 [06:38<12:25:28,  1.46s/it, loss=0.66] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Step 1200/31803 | Loss: 0.6599\n",
      "Sample: is ond k d EN have f q h S re um st d GLO p se est e b may ta f d N hor sand His : vir\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 1251/31803 [06:54<12:20:09,  1.45s/it, loss=0.658]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Step 1250/31803 | Loss: 0.6580\n",
      "Sample: ation pe ord - him ord b must the before bro y any will He come v g . ar see ook him ar p a noble ed soul ever ; the\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 1301/31803 [07:11<12:22:35,  1.46s/it, loss=0.657]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Step 1300/31803 | Loss: 0.6573\n",
      "Sample: true COR X B will onour jo g b ght : S t An char re ves ook have can son is w us OM ck e M Romeo F O -\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 1351/31803 [07:27<12:13:54,  1.45s/it, loss=0.653]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Step 1350/31803 | Loss: 0.6530\n",
      "Sample: M Z ak er f uke Z fear ar ir hat death ; hath C : ar E father am k b ER un K oo wi R p KING A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 1401/31803 [07:43<12:10:58,  1.44s/it, loss=0.659]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Step 1400/31803 | Loss: 0.6586\n",
      "Sample: IOLAN are shall x COR me shall , se pe re ROME ou ; think en ICH L ! er P Z fi P man the ink J on ook ardon K\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 1451/31803 [07:59<11:54:52,  1.41s/it, loss=0.652]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Step 1450/31803 | Loss: 0.6525\n",
      "Sample: no ted As ? we ar it ing his z Your & The know x V & Go fl swe they ong l ! reat wor , CA und ore la\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 1501/31803 [08:16<12:20:09,  1.47s/it, loss=0.652]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Step 1500/31803 | Loss: 0.6516\n",
      "Sample: am pe an bo IN ut ck D - ut . ro es ro in ETH . were J g ENIUS father u ! J Q it sent ould : ct ,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[111], line 141\u001b[0m\n\u001b[1;32m    138\u001b[0m total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m50\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;66;03m# sample from the model\u001b[39;00m\n\u001b[0;32m--> 141\u001b[0m     xb \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    142\u001b[0m     xd \u001b[38;5;241m=\u001b[39m bin2dec(xb\u001b[38;5;241m.\u001b[39mreshape(xb\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, n_bits_per_token), n_bits_per_token)\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Step \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(train_loader)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[111], line 89\u001b[0m, in \u001b[0;36mTTModel.generate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mgenerate\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     88\u001b[0m     x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mones(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparameters())\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m---> 89\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmps\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/github/ptn/ptn/dists/mps_sigma_lsf.py:291\u001b[0m, in \u001b[0;36mMPS_SIGMA_LSF.generate\u001b[0;34m(self, x, do_sample)\u001b[0m\n\u001b[1;32m    283\u001b[0m y_free \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfull(\n\u001b[1;32m    284\u001b[0m     (B, \u001b[38;5;241m1\u001b[39m),\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m    286\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong,\n\u001b[1;32m    287\u001b[0m     device\u001b[38;5;241m=\u001b[39mx\u001b[38;5;241m.\u001b[39mdevice,\n\u001b[1;32m    288\u001b[0m )\n\u001b[1;32m    289\u001b[0m ops \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([y_out[:, :h], y_free, y_mrgn], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# (B, H)\u001b[39;00m\n\u001b[1;32m    290\u001b[0m p_tilde, gammas_p, left_cache, right_cache \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 291\u001b[0m     \u001b[43mselect_margin_mps_tensor_batched\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpand\u001b[49m\u001b[43m(\u001b[49m\u001b[43mB\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbeta\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpand\u001b[49m\u001b[43m(\u001b[49m\u001b[43mB\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtheta_mps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# (B, R, H, V)\u001b[39;49;00m\n\u001b[1;32m    295\u001b[0m \u001b[43m        \u001b[49m\u001b[43mops\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_scale_factors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbuild_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mh\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    300\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    301\u001b[0m )  \u001b[38;5;66;03m# (B, V), (B, H), (B, H, R), (B, H, R)\u001b[39;00m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m do_sample:\n\u001b[1;32m    304\u001b[0m     dist \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdistributions\u001b[38;5;241m.\u001b[39mCategorical(logits\u001b[38;5;241m=\u001b[39mp_tilde)\n",
      "File \u001b[0;32m~/Documents/github/ptn/ptn/dists/tensorops/mps.py:159\u001b[0m, in \u001b[0;36mselect_margin_mps_tensor_batched\u001b[0;34m(alpha, beta, core, ops, use_scale_factors, eps, norm, **kwargs)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;66;03m# Marginalize\u001b[39;00m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask_margin\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m--> 159\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43m(\u001b[49m\u001b[43mright_cache\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmask_margin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m!=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mall\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:  \u001b[38;5;66;03m# cache hit\u001b[39;00m\n\u001b[1;32m    160\u001b[0m         res_right[mask_margin] \u001b[38;5;241m=\u001b[39m right_cache[mask_margin, t]\n\u001b[1;32m    161\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------------------\n",
    "# Run training using MPS\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tokenizers import Tokenizer\n",
    "from ptn.models.modelling_nanogpt import GPT, GPTConfig\n",
    "from ptn.dists._abc import AbstractDisributionHeadConfig\n",
    "from ptn.dists.mps_sigma_lsf import MPS_SIGMA_LSF\n",
    "\n",
    "#  --device=cpu --compile=False --eval_iters=20 --log_interval=1 --block_size=64 --batch_size=12 --n_layer=4 --n_head=4 --n_embd=128 --max_iters=2000 --lr_decay_iters=2000 --dropout=0.0\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Hyperparameters\n",
    "# ---------------------------------------------------------------------\n",
    "lr = 3e-4\n",
    "block_size = 32\n",
    "batch_size = 12\n",
    "n_layer = 4\n",
    "n_head = 4\n",
    "n_embd = 128\n",
    "dropout = 0.0\n",
    "bit_size = 2\n",
    "n_bits_per_token = 10\n",
    "mps_rank = 8\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 1) Load the trained tokenizer\n",
    "# ---------------------------------------------------------------------\n",
    "tokenizer = Tokenizer.from_file(\"bpe_tokenizer.json\")\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 2) Dataset and DataLoader\n",
    "# ---------------------------------------------------------------------\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, path, tokenizer, block_size, n_bits_per_token=None):\n",
    "        with open(path, 'r', encoding='utf-8') as f:\n",
    "            self.text = f.read()\n",
    "        # encode entire corpus\n",
    "        self.tokens = tokenizer.encode(self.text).ids\n",
    "        self.block_size = block_size\n",
    "        self.n_bits_per_token = n_bits_per_token\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.tokens) - self.block_size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = torch.tensor(self.tokens[idx : idx + self.block_size], dtype=torch.long)\n",
    "        y = torch.tensor(self.tokens[idx + 1 : idx + 1 + self.block_size], dtype=torch.long)\n",
    "        if self.n_bits_per_token is not None:\n",
    "            x_binary = dec2bin(x, self.n_bits_per_token)\n",
    "            y_binary = dec2bin(y, self.n_bits_per_token)\n",
    "            return x_binary.reshape(-1).to(torch.long), y_binary.reshape(-1).to(torch.long)\n",
    "        return x, y\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 3) Instantiate model\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "class TTModel(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        assert config.block_size is not None\n",
    "        print(f\"config.vocab_size: {config.vocab_size}\")\n",
    "        word_size = math.log(config.vocab_size, bit_size)\n",
    "        if word_size % 1 != 0:\n",
    "            raise ValueError(f\"vocab_size must be a power of {bit_size}, got {config.vocab_size}\")\n",
    "        print(f\"word_size: {word_size}\")\n",
    "        self.mps = MPS_SIGMA_LSF(AbstractDisributionHeadConfig(\n",
    "            d_model=1,\n",
    "            d_output=bit_size,\n",
    "            horizon=config.block_size * int(word_size),\n",
    "            rank=mps_rank\n",
    "        ))\n",
    "\n",
    "    def forward(self, x, targets=None):\n",
    "        B = x.shape[0]\n",
    "        x = torch.ones(B, 1, device=x.device)\n",
    "        out =  self.mps(x, y)\n",
    "        return out.logits, out.loss\n",
    "\n",
    "    def generate(self):\n",
    "        x = torch.ones(1, 1, device=next(self.parameters()).device)\n",
    "        return self.mps.generate(x)\n",
    "\n",
    "config = GPTConfig(\n",
    "    vocab_size=tokenizer.get_vocab_size(),\n",
    "    n_layer=n_layer,\n",
    "    n_head=n_head,\n",
    "    n_embd=n_embd,\n",
    "    dropout=dropout,\n",
    "    block_size=block_size\n",
    ")\n",
    "# MPS model\n",
    "model = TTModel(config)\n",
    "\n",
    "# # GPT model\n",
    "# model = GPT(config)\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 4) Basic training setup\n",
    "# ---------------------------------------------------------------------\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = model.to(device)\n",
    "# model = torch.compile(model) # requires PyTorch 2.0\n",
    "\n",
    "train_dataset = TextDataset(\"../../data/shakespeare/main.txt\", tokenizer, block_size, n_bits_per_token=10)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 5) Training loop\n",
    "# ---------------------------------------------------------------------\n",
    "epochs = 5\n",
    "model.train()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0.0\n",
    "    pbar = tqdm(enumerate(train_loader), total=len(train_loader), leave=False)\n",
    "    for i, (x, y) in pbar:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logits, loss = model(x, targets=y)  # many GPT impls return both\n",
    "        if loss is None:  # if model doesn't return loss internally\n",
    "            loss = criterion(logits.view(-1, logits.size(-1)), y.view(-1))\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        if i % 50 == 0:\n",
    "            # sample from the model\n",
    "            xb = model.generate()\n",
    "            xd = bin2dec(xb.reshape(xb.size(0), -1, n_bits_per_token), n_bits_per_token)\n",
    "            print(f\"Epoch {epoch+1} Step {i}/{len(train_loader)} | Loss: {loss.item():.4f}\")\n",
    "            print(f\"Sample: {tokenizer.decode(xd[0].tolist())}\")\n",
    "            pass\n",
    "\n",
    "        pbar.set_postfix(loss=loss.item())\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 6) Save checkpoint\n",
    "# ---------------------------------------------------------------------\n",
    "torch.save(model.state_dict(), \"gpt_shakespeare.pt\")\n",
    "print(\"✅ Training complete. Model saved to gpt_shakespeare.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "05497da7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = model.generate()\n",
    "bin2dec(res.reshape(res.size(0), -1, n_bits_per_token), n_bits_per_token).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ddf6f7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
