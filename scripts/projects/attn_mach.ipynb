{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "113b6bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class AttnMach(torch.nn.Module):\n",
    "    def __init__(self, n_vars, d_vocab, d_hidden):\n",
    "        super().__init__()\n",
    "        self.n_vars = n_vars\n",
    "        self.d_vocab = d_vocab\n",
    "        self.d_hidden = d_hidden\n",
    "\n",
    "        self._w_v = torch.nn.Parameter(torch.randn(1, d_vocab))\n",
    "        self._w_q = torch.nn.Parameter(torch.randn(d_hidden, d_vocab))\n",
    "        self._w_k = torch.nn.Parameter(torch.randn(d_hidden, d_vocab))\n",
    "\n",
    "    @property\n",
    "    def w_v(self) -> torch.Tensor:\n",
    "        return self._w_v.abs()\n",
    "\n",
    "    @property\n",
    "    def w_q(self) -> torch.Tensor:\n",
    "        return self._w_q.abs()\n",
    "\n",
    "    @property\n",
    "    def w_k(self) -> torch.Tensor:\n",
    "        return self._w_k.abs()\n",
    "\n",
    "    def _contract(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        q = torch.einsum(\"bvd,hd->bvh\", x, self.w_q)\n",
    "        k = torch.einsum(\"bvd,hd->bvh\", x, self.w_k)\n",
    "        v = torch.einsum(\"bvd,hd->bvh\", x, self.w_v)\n",
    "        y = F.scaled_dot_product_attention(q, k, v, attn_mask=None, dropout_p=0.0, is_causal=False)\n",
    "        return y\n",
    "\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Computes log prob of seqs.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): (B, n_vars, d_vocab)\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: (B,)\n",
    "        \"\"\"\n",
    "        assert torch.all(x < self.d_vocab), f\"Expected input to be in range [0, {self.d_vocab}), got max {x.max()}\"\n",
    "        x = torch.nn.functional.one_hot(x, num_classes=self.d_vocab).to(torch.get_default_dtype())  # (B, n_vars, d_vocab)\n",
    "\n",
    "        p_tilde = self._contract(x)\n",
    "        z = self._contract(torch.ones_like(x))\n",
    "        print(p_tilde.shape, z.shape)\n",
    "\n",
    "        if (p_tilde > z.prod(dim=-1)).any():\n",
    "            print(\"Error: p_tilde > z\")\n",
    "\n",
    "        loss = z.log().sum(dim=-1) - p_tilde.squeeze(-1).log().sum(dim=-1)\n",
    "        return loss.mean()\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "fd52071f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4, 1]) torch.Size([1, 4, 1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(-0.1248, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_vocab = 2\n",
    "d_hidden = 8\n",
    "n_vars = 4\n",
    "\n",
    "x = torch.randint(0, d_vocab, (1, n_vars))\n",
    "# print(x.shape)\n",
    "\n",
    "attn_mach = AttnMach(n_vars, d_vocab, d_hidden)\n",
    "loss = attn_mach(x)\n",
    "loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9e8b0d39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 1])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce05a8d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
