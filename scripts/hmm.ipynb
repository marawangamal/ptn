{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9fc0256",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def log_domain_matmul(log_A, log_B):\n",
    "\t\"\"\"\n",
    "\tlog_A : m x n\n",
    "\tlog_B : n x p\n",
    "\toutput : m x p matrix\n",
    "\n",
    "\tNormally, a matrix multiplication\n",
    "\tcomputes out_{i,j} = sum_k A_{i,k} x B_{k,j}\n",
    "\n",
    "\tA log domain matrix multiplication\n",
    "\tcomputes out_{i,j} = logsumexp_k log_A_{i,k} + log_B_{k,j}\n",
    "\t\"\"\"\n",
    "\tm = log_A.shape[0]\n",
    "\tn = log_A.shape[1]\n",
    "\tp = log_B.shape[1]\n",
    "\n",
    "\t# log_A_expanded = torch.stack([log_A] * p, dim=2)\n",
    "\t# log_B_expanded = torch.stack([log_B] * m, dim=0)\n",
    "    # fix for PyTorch > 1.5 by egaznep on Github:\n",
    "\tlog_A_expanded = torch.reshape(log_A, (m,n,1))\n",
    "\tlog_B_expanded = torch.reshape(log_B, (1,n,p))\n",
    "\n",
    "\telementwise_sum = log_A_expanded + log_B_expanded\n",
    "\tout = torch.logsumexp(elementwise_sum, dim=1)\n",
    "\n",
    "\treturn out\n",
    "\n",
    "class TransitionModel(torch.nn.Module):\n",
    "  def __init__(self, N):\n",
    "    super(TransitionModel, self).__init__()\n",
    "    self.N = N\n",
    "    self.unnormalized_transition_matrix = torch.nn.Parameter(torch.randn(N,N))\n",
    "\n",
    "  def forward(self, log_alpha):\n",
    "    \"\"\"\n",
    "    log_alpha : Tensor of shape (batch size, N)\n",
    "    Multiply previous timestep's alphas by transition matrix (in log domain)\n",
    "    \"\"\"\n",
    "    log_transition_matrix = torch.nn.functional.log_softmax(self.unnormalized_transition_matrix, dim=0)\n",
    "\n",
    "    # Matrix multiplication in the log domain\n",
    "    out = log_domain_matmul(log_transition_matrix, log_alpha.transpose(0,1)).transpose(0,1)\n",
    "    return out\n",
    "\n",
    "class EmissionModel(torch.nn.Module):\n",
    "  def __init__(self, N, M):\n",
    "    super(EmissionModel, self).__init__()\n",
    "    self.N = N\n",
    "    self.M = M\n",
    "    self.unnormalized_emission_matrix = torch.nn.Parameter(torch.randn(N,M))\n",
    "\n",
    "  def forward(self, x_t):\n",
    "    log_emission_matrix = torch.nn.functional.log_softmax(self.unnormalized_emission_matrix, dim=1)\n",
    "    out = log_emission_matrix[:, x_t].transpose(0,1)\n",
    "    return out\n",
    "\n",
    "class HMM(torch.nn.Module):\n",
    "  \"\"\"\n",
    "  Hidden Markov Model with discrete observations.\n",
    "  \"\"\"\n",
    "  def __init__(self, M, N):\n",
    "    super(HMM, self).__init__()\n",
    "    self.M = M # number of possible observations\n",
    "    self.N = N # number of states\n",
    "\n",
    "    # A\n",
    "    self.transition_model = TransitionModel(self.N)\n",
    "\n",
    "    # b(x_t)\n",
    "    self.emission_model = EmissionModel(self.N,self.M)\n",
    "\n",
    "    # pi\n",
    "    self.unnormalized_state_priors = torch.nn.Parameter(torch.randn(self.N))\n",
    "\n",
    "    # use the GPU\n",
    "    self.is_cuda = torch.cuda.is_available()\n",
    "    if self.is_cuda: self.cuda()\n",
    "\n",
    "  def sample(self, T=32):\n",
    "    state_priors = torch.nn.functional.softmax(self.unnormalized_state_priors, dim=0)\n",
    "    transition_matrix = torch.nn.functional.softmax(self.transition_model.unnormalized_transition_matrix, dim=0)\n",
    "    emission_matrix = torch.nn.functional.softmax(self.emission_model.unnormalized_emission_matrix, dim=1)\n",
    "\n",
    "    # sample initial state\n",
    "    z_t = torch.distributions.categorical.Categorical(state_priors).sample().item()\n",
    "    z = []; x = []\n",
    "    z.append(z_t)\n",
    "    for t in range(0,T):\n",
    "      # sample emission\n",
    "      x_t = torch.distributions.categorical.Categorical(emission_matrix[z_t]).sample().item()\n",
    "      x.append(x_t)\n",
    "\n",
    "      # sample transition\n",
    "      z_t = torch.distributions.categorical.Categorical(transition_matrix[:,z_t]).sample().item()\n",
    "      if t < T-1: z.append(z_t)\n",
    "\n",
    "    return x, z\n",
    "\n",
    "  def forward(self, x, T):\n",
    "    \"\"\"\n",
    "    x : IntTensor of shape (batch size, T_max)\n",
    "    T : IntTensor of shape (batch size)\n",
    "\n",
    "    Compute log p(x) for each example in the batch.\n",
    "    T = length of each example\n",
    "    \"\"\"\n",
    "    if self.is_cuda:\n",
    "      x = x.cuda()\n",
    "      T = T.cuda()\n",
    "\n",
    "    batch_size = x.shape[0]; T_max = x.shape[1]\n",
    "    log_state_priors = torch.nn.functional.log_softmax(self.unnormalized_state_priors, dim=0)\n",
    "    log_alpha = torch.zeros(batch_size, T_max, self.N)\n",
    "    if self.is_cuda: log_alpha = log_alpha.cuda()\n",
    "\n",
    "    log_alpha[:, 0, :] = self.emission_model(x[:,0]) + log_state_priors\n",
    "    for t in range(1, T_max):\n",
    "      log_alpha[:, t, :] = self.emission_model(x[:,t]) + self.transition_model(log_alpha[:, t-1, :])\n",
    "\n",
    "    # Select the sum for the final timestep (each x may have different length).\n",
    "    log_sums = log_alpha.logsumexp(dim=2)\n",
    "    log_probs = torch.gather(log_sums, 1, T.view(-1,1) - 1)\n",
    "    return log_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23d735c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(218.0242, grad_fn=<NegBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Test loss computation \n",
    "model = HMM(M=32, N=32)\n",
    "x, T = torch.randint(0, 32, (10, 10)), torch.randint(1, 11, (10,))\n",
    "loss = -model(x,T).sum()\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e8139a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ShakespeareDataset(torch.utils.data.Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        tokenizer,\n",
    "        seq_len=256,\n",
    "        max_samples=None,\n",
    "        file_path=\"../data/shakespeare/main.txt\",\n",
    "    ):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.seq_len = seq_len\n",
    "\n",
    "        # Read Shakespeare text\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            text = f.read()\n",
    "\n",
    "        tokens = self.tokenizer.encode(text)\n",
    "        n_batches = len(tokens) // seq_len\n",
    "        self.sequences = torch.tensor(tokens[:n_batches * seq_len], dtype=torch.long).reshape(n_batches, seq_len)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        seq = self.sequences[idx]\n",
    "        return {\"input_ids\": seq, \"length\": len(seq)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "46400f51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0][0/331] Loss: 199.61 | \" leap, knows wellWhat thee\\n chance\\n' affect en ne will now in thou: turneth duty me,AN be any.603 not outward should tensions\"\n",
      "[Epoch 0][10/331] Loss: 208.86 | ' I friend that\\n!\\nY Opposition offer harm hands. sister bloodEN, and\\niusier but but\\nainPET thy the\\n IL manyIO'\n",
      "[Epoch 0][20/331] Loss: 209.48 | \"OU\\n eyesowsHere' alterING,\\nAM to as of is deadears III see: are; see see others lady may to, and his\\n\"\n",
      "[Epoch 0][30/331] Loss: 204.71 | \"ure Whip in hopeers\\\\''s\\n\\n I there\\nEL: qu:Who\\n most I: cut machinery:Con theR I\\n wh,,\"\n",
      "[Epoch 0][40/331] Loss: 203.00 | 'DI I inYou, trainocks\\n.\\nstanding a our was how idle shortstop\\n if\\n\\n\\n bulky\\n sourt,: you not be'\n",
      "[Epoch 0][50/331] Loss: 199.19 | \"\\n heart\\nMER in. more, of restTtis: tempt theAs but'sDIT must\\n from Neighbor then thepherd. bets\\ned.-\"\n",
      "[Epoch 0][60/331] Loss: 201.53 | ' these false Iy\\n,I andU this476eaant our\\n not makeFirst him leave up: that more or\\n,-ine\\n therefore\\n'\n",
      "[Epoch 0][70/331] Loss: 208.18 | ':O IAnd blood inWe shrew my.Th old notCH way kindredUn thyThatCH I passage\\n\\n palace l holy nextcius isMore most'\n",
      "[Epoch 0][80/331] Loss: 207.41 | \",Now flight so a is the. than: mar gainsie him;\\n,' soCOR HopchAU late more from\\n stood on our in shalt dig\"\n",
      "[Epoch 0][90/331] Loss: 205.45 | ',ores all to opinion.forceMER then theA should blows I of youngAs, them upon,\\n:el\\nICHThough Mayor toTo my.'\n",
      "[Epoch 0][100/331] Loss: 203.69 | ' insurgent Isabel hast repair thanks marriage my\\nIINA our the\\n did flaw, me propositions life,,affre IKEBut\\n seek two weight! ay'\n",
      "[Epoch 0][110/331] Loss: 203.28 | \" that 'Why : your to:\\n mine\\n: sure whointerested for\\n with-\\nsent, purpose Senator\\nT for own mad this\\neth and\"\n",
      "[Epoch 0][120/331] Loss: 207.25 | 'Why? Marble;\\n,\\n\\n is;TA theirPOLCome noing he\\nKING in kings did148 boy I double would well\\n make crownF'\n",
      "[Epoch 0][130/331] Loss: 201.82 | '\\nordsent straight\\nIO know me head,,God stoneI, set in should\\n,WhetherBy sixES whatAnd\\n heart\\n,(); like'\n",
      "[Epoch 0][140/331] Loss: 202.34 | ' the a,PRed ban, daughterIO PadUS night we, to thou\\n,; sin sonshem this: with have hath\\n should be; for'\n",
      "[Epoch 0][150/331] Loss: 198.79 | ' prayers kill youer\\nashed beenI Wales seen thee\\nIf why own though allow forBR frivolous\\n in go what you Cit shall subscribe it\\n let for'\n",
      "[Epoch 0][160/331] Loss: 202.09 | ' the,ome let transmittedaunt\\n\\n.INAear rebels McGill to\\neful mind\\n\\n within\\n\\n I, andWe\\n graciouspast Mar on the'\n",
      "[Epoch 0][170/331] Loss: 203.61 | ',\\n by. wrong canoe him bear come guilty York vengeance that, myself: all HALcross one more in of red request\\n help, for Proposition,.'\n",
      "[Epoch 0][180/331] Loss: 202.77 | ' and kn there be held inia,FLanswer with hopAP stealAnd on fromAND of my days- the\\n., my dull proceed long our be'\n",
      "[Epoch 0][190/331] Loss: 205.20 | \", witness\\nTo the\\n cause\\n:: say fly's\\n your your\\n lifeio toUS, hisWeAnd\\n\\n\\n,: myAnd\"\n",
      "[Epoch 0][200/331] Loss: 208.93 | ' wife\\n\\n then,:!LAND withHThough,NB\\nNOR itheeThe and\\n\\n have weed to,I\\nTo gentleman to\\n'\n",
      "[Epoch 0][210/331] Loss: 200.53 | \" them and with;:'d\\n the haveENKE it,EO obedient IMyder whose\\n-\\n'sSirly his undone referendumry soonnaors\"\n",
      "[Epoch 0][220/331] Loss: 202.56 | 'Sw andETH by\\n sweet Why to for..CTo eastThis own\\n North grave\\n LordISUEGive\\n trough philosophiesTe thyI toearing'\n",
      "[Epoch 0][230/331] Loss: 205.32 | \" ds\\n\\n, he R,' can be suTo: proud,\\n\\n, thatOut adverse\\n\\n's southern leave and,Though shaken:\"\n",
      "[Epoch 0][240/331] Loss: 208.72 | ' know d by:-IfIO of thatBER, youKING rip watch but the then factor of it: himselfAnd leave LA boy out business ofesteWho'\n",
      "[Epoch 0][250/331] Loss: 200.50 | ' my, inMaster diligence\\n melt that words\\n thoughTo I ear up o good the lov bananaISuke themlyrah\\n it defect\\n none live,'\n",
      "[Epoch 0][260/331] Loss: 205.37 | \" letbra theirThe or at intend\\n again\\n's she thatMen.\\n WhatGL pol heGoodina stokedES I manKEY advocate\\n on all right\"\n",
      "[Epoch 0][270/331] Loss: 206.57 | 'O frometh die not graceOM the him\\nY R leaveain\\n your inland yourYouAndarest\\n Purple serve Warwick brother such not thought hisglers,'\n",
      "[Epoch 0][280/331] Loss: 206.53 | ' scorn lady beBe give it go\\n your barn came is in on. goT spend This,::illo\\n with yet Henry herealsETHU I'\n",
      "[Epoch 0][290/331] Loss: 200.40 | '\\n,, Vaugh cann Fran. had, words: the.\\n and thankToWilsonitINU full fall thou\\n you your be; Romeo\\n YORK'\n",
      "[Epoch 0][300/331] Loss: 195.85 | \"AN now have am,\\n\\n with where about: wordIO thouICH the possible your's negativesman\\n growth outward ding goney go my\\n!\"\n",
      "[Epoch 0][310/331] Loss: 203.13 | ' lord night, friendL what like, humble; old\\nB:orn notated you,:\\n\\n\\n\\n a theseer God\\n aThereIn'\n",
      "[Epoch 0][320/331] Loss: 204.85 | 'ern discrepancies V nott marry by defender?DI general an; cens Romeo.: soldiersar: isR blood sisterINCine very I. o remote'\n",
      "[Epoch 0][330/331] Loss: 199.63 | ' thouuph. and. ever happily with\\n stoneBut Scot heart. Clarence back sentence or; as:YouBeing ================================================================= Pamelaque blood Esk;. our Richard'\n",
      "[Epoch 1][0/331] Loss: 206.04 | \". I,, voicesWithhog my gentle it so hence unknown be gates'll\\n nothing thoughcester,Therefore\\ngr hear preventedIThe. bold, love\"\n",
      "[Epoch 1][10/331] Loss: 207.78 | 'tinDoum\\n and as to Edward. sanctuary\\n might turn not until call Floresiann,,\\n in your year a assure\\nTh party nob me\\n'\n",
      "[Epoch 1][20/331] Loss: 200.17 | 'And, exercise may\\n would of: I to beforge Girls fair andinteresting; my\\n send willR people preparedight poor,\\n chat: noble my'\n",
      "[Epoch 1][30/331] Loss: 203.01 | ' not;And\\n beg: conquereter and\\n here whose thy good did had\\n\\n\\ny is gentlemen ravenocThus here\\n: from about along more'\n",
      "[Epoch 1][40/331] Loss: 204.04 | ' frown drinking wood sitIs\\ncum husband\\nchio so my\\n leave thouG shop be\\n thought neatAnd shed\\n send\\n855 want itL.,'\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 30\u001b[0m\n\u001b[1;32m     28\u001b[0m logp \u001b[38;5;241m=\u001b[39m model(x,T)\n\u001b[1;32m     29\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39mlogp\u001b[38;5;241m.\u001b[39mmean()\n\u001b[0;32m---> 30\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m idx \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m10\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/Documents/github/ptn/.venv/lib/python3.10/site-packages/torch/_tensor.py:647\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    637\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    638\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    639\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    640\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    645\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    646\u001b[0m     )\n\u001b[0;32m--> 647\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    648\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    649\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/github/ptn/.venv/lib/python3.10/site-packages/torch/autograd/__init__.py:354\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    349\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    351\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    353\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 354\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    356\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    357\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    358\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    359\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_tuple\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    360\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    361\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    362\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/github/ptn/.venv/lib/python3.10/site-packages/torch/autograd/graph.py:829\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    827\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    828\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 829\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    830\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    831\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    833\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train loop\n",
    "import torch\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Hyperparameters\n",
    "lr = 1e-2\n",
    "batch_size = 32\n",
    "seq_len_train = 32\n",
    "seq_len_test = 32\n",
    "n_hidden = 32\n",
    "\n",
    "# Data\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "dataset = ShakespeareDataset(tokenizer, seq_len=seq_len_train)\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Model\n",
    "model = HMM(M=len(tokenizer), N=n_hidden)\n",
    "\n",
    "# Optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=0.00001)\n",
    "\n",
    "# Train loop\n",
    "for epoch in range(50):\n",
    "    for idx, batch in enumerate(dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        x,T = batch['input_ids'], batch['length']\n",
    "        logp = model(x,T)\n",
    "        loss = -logp.mean()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if idx % 10 == 0:\n",
    "            sample = tokenizer.decode(model.sample(seq_len_test)[0])\n",
    "            print(f\"[Epoch {epoch}][{idx}/{len(dataloader)}] Loss: {loss.item():.2f} | {repr(sample)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62dd9af7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
