{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f4945c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "import os, certifi\n",
    "from mtp.mheads._abc import AbstractDisributionHeadConfig\n",
    "from mtp.mheads import MHEADS\n",
    "os.environ[\"SSL_CERT_FILE\"] = certifi.where()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b34aecc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torch.nn.functional as F, matplotlib.pyplot as plt\n",
    "from IPython.display import display, update_display, HTML\n",
    "\n",
    "def qual_eval(model, handle=None, digit=0, shape=(28,28), clear=False, px=120):\n",
    "    if not hasattr(qual_eval, \"_store\"): qual_eval._store = {}\n",
    "    if clear and handle is not None:\n",
    "        update_display(HTML(\"\"), display_id=handle.display_id)\n",
    "        qual_eval._store.pop(handle.display_id, None); return handle\n",
    "\n",
    "    dev = next(model.parameters()).device\n",
    "    with torch.no_grad():\n",
    "        z = F.one_hot(torch.tensor([digit], device=dev), num_classes=10).float()\n",
    "        img = model.generate(z)[0].detach().cpu().view(*shape).numpy()\n",
    "\n",
    "    new = handle is None or getattr(handle, \"display_id\", None) not in qual_eval._store\n",
    "    if new:\n",
    "        dpi = 100\n",
    "        fig, ax = plt.subplots(figsize=(px/dpi, px/dpi), dpi=dpi)\n",
    "        im = ax.imshow(img, cmap=\"gray\", interpolation=\"nearest\")\n",
    "        ax.axis(\"off\"); fig.subplots_adjust(0,0,1,1)\n",
    "        handle = display(fig, display_id=True); plt.close(fig)\n",
    "        qual_eval._store[handle.display_id] = (im, fig)\n",
    "    else:\n",
    "        im, fig = qual_eval._store[handle.display_id]\n",
    "        im.set_data(img)\n",
    "        # resize if px changed\n",
    "        fig.set_size_inches(px/fig.dpi, px/fig.dpi)\n",
    "        update_display(fig, display_id=handle.display_id)\n",
    "    return handle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "af4fdfa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set has 60000 instances\n",
      "Validation set has 10000 instances\n"
     ]
    }
   ],
   "source": [
    "# Make the image binary: threshold at 0.5 after ToTensor, then convert to long (int)\n",
    "transform = transforms.Compose([transforms.ToTensor(), lambda x: (x > 0.5).long()])\n",
    "\n",
    "# Create datasets for training & validation, download if necessary\n",
    "training_set = torchvision.datasets.MNIST(\n",
    "    \"./data\", train=True, transform=transform, download=True\n",
    ")\n",
    "validation_set = torchvision.datasets.MNIST(\n",
    "    \"./data\", train=False, transform=transform, download=True\n",
    ")\n",
    "\n",
    "# Create data loaders for our datasets; shuffle for training, not for validation\n",
    "training_loader = torch.utils.data.DataLoader(training_set, batch_size=4, shuffle=True)\n",
    "validation_loader = torch.utils.data.DataLoader(\n",
    "    validation_set, batch_size=4, shuffle=False\n",
    ")\n",
    "\n",
    "# Report split sizes\n",
    "print(\"Training set has {} instances\".format(len(training_set)))\n",
    "print(\"Validation set has {} instances\".format(len(validation_set)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5c5747d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 480x150 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get the first batch from the training loader\n",
    "dataiter = iter(training_loader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# Show up to the first 10 images in the batch using seaborn\n",
    "num_images = min(10, images.shape[0])\n",
    "plt.figure(figsize=(num_images * 1.2, 1.5))  # Make images smaller\n",
    "\n",
    "for i in range(num_images):\n",
    "    plt.subplot(1, num_images, i + 1)\n",
    "    img = images[i].squeeze().numpy()\n",
    "    sns.heatmap(img, cmap='gray', cbar=False, xticklabels=False, yticklabels=False, square=True)\n",
    "    plt.title(f\"{labels[i].item()}\", fontsize=8)\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.suptitle(\"First Batch Images (Labels shown above)\", y=1.05)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "40b5571c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/15000 [00:00<?, ?it/s, loss=0.936]"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIwAAACMCAYAAACuwEE+AAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjYsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvq6yFwwAAAAlwSFlzAAAPYQAAD2EBqD+naQAAA6FJREFUeJzt3duu3CgQBdB4NP//yx6dx2l1x2y6Cki01lskB6yjLRpxKV/3fd+/YNA/ow/CD4EhIjBEBIaIwBARGCICQ0RgiAgMkX9HH7yu63//nlkgfm3jndd2Z/7Pqve4H/rtePd37a5crDfCEBEYIgJDzxxmxtNv+Lvf3pHf/W//z0i/M+/xpGquMTPPq3oXIwwRgSEiMEQEhp5Jb8WCWsVC1sgCWsXC1sy7Xw/PrHr3pz6+6ccIQ0RgiAgM+xbuOjbBOn7TK+YjVfOvjvlWJyMMEYEhIjCsOUA1+8yOg0zfPv+p3ycz85OKuVPXwa0fRhgiAkNEYFizl/ROx6GjCicfxr4a5iwVB6w+McIQERgiAkNEYFiz+ThzGGhEx4GhikXHVTcN7oF375hsO0BFC4EhIjDs23xccbCn4kDzzCLkSdUbXrn5yLEEhojAcM5FtlUHqdM5S0Ub71Ssw4zMx3Zu8hphiAgMEYEhIjDsu/mYnvyqWtj7U/q9mhbybD5yLIEhIjCcU3b11aqbfxVG2rwLFgw7boN2VnMwwhARGCICQ+Qa/dD5qoPHK27xVW3o3Q1ziVPe4xMjDBGBISIw9MxhVh3i2XUZbkW1qHvRYaiZd7eXRAuBISIwRASGczYfO0tn/a6fUyfoV0HJ2BHKrnIMgSEiMKxZuKuq4vTURsciXNWn9K7wXU/q9+k9PjHCEBEYIgLDviqaOz8t922/M3One8Hnj2ee6azuYIQhIjBEBIaIwHBO2dVdbawqP3a/tLNiEW7k3dx85BgCQ0RgOPebjxXVDE7+jb8KNj2f2hxt99t+PzHCEBEYIgLDvgNUuyoRdFR8WHUD81r02b+0jU+MMEQEhojA8HdV0dxVIXNFNYd3Vs2/rMOwhMAQERgiAsOaA1SrbgRUlFKv6GdX5Ym74O+s7CrbCAwRgeGc71ZXOGUjcabda9O8p5MRhojAEBEY1mw+VpRBrzro01HCfWTecy343M3KTwyPMMIQERgiAkNEYDjn1sCpJdxH2qhwFVSa6Co373tJLCEwRASGc7/5ODPX6KqA0OHetHC3slqFEYaIwBARGM7ZfKwonb7rNmFFtaxX7/4eu252zjLCEBEYIgLDOdUbVq1/VBygemqza842Y1e/P4wwRASGiMAQERh6Nh87JlpdtwYqSreO9HvKdzEryqs5QEULgSEiMJx7CJw/nxGGiMAQERgiAkNEYIgIDBGBISIwRASGX4n/AEevVijQUQO9AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 120x120 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|â–‹         | 974/15000 [13:57<3:21:02,  1.16it/s, loss=0.254]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 41\u001b[0m\n\u001b[1;32m     39\u001b[0m     pbar\u001b[38;5;241m.\u001b[39mset_postfix(loss\u001b[38;5;241m=\u001b[39mloss\u001b[38;5;241m.\u001b[39mitem())\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;66;03m# Sample\u001b[39;00m\n\u001b[0;32m---> 41\u001b[0m     h \u001b[38;5;241m=\u001b[39m \u001b[43mqual_eval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdigit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m   \u001b[38;5;66;03m# reuse same output cell\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[19], line 13\u001b[0m, in \u001b[0;36mqual_eval\u001b[0;34m(model, handle, digit, shape, clear, px)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m     12\u001b[0m     z \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mone_hot(torch\u001b[38;5;241m.\u001b[39mtensor([digit], device\u001b[38;5;241m=\u001b[39mdev), num_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[0;32m---> 13\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mz\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m*\u001b[39mshape)\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m     15\u001b[0m new \u001b[38;5;241m=\u001b[39m handle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(handle, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdisplay_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m qual_eval\u001b[38;5;241m.\u001b[39m_store\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m new:\n",
      "File \u001b[0;32m~/Documents/github/mtl/mtp/mheads/moe_proj.py:137\u001b[0m, in \u001b[0;36mMoEProjector.generate\u001b[0;34m(self, x, do_sample)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m h \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(H):\n\u001b[1;32m    135\u001b[0m     \u001b[38;5;66;03m# Compute log P(y_h | x, y_1, ..., y_h-1)\u001b[39;00m\n\u001b[1;32m    136\u001b[0m     lsm_a \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mlog_softmax(alphas_tilde, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# (B, R, 1)\u001b[39;00m\n\u001b[0;32m--> 137\u001b[0m     lsm_cp \u001b[38;5;241m=\u001b[39m \u001b[43mcp_params_tilde\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_softmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# (B, R, H, V)\u001b[39;00m\n\u001b[1;32m    138\u001b[0m     lsm_select \u001b[38;5;241m=\u001b[39m lsm_cp\u001b[38;5;241m.\u001b[39mgather(  \u001b[38;5;66;03m# (B, R, H, V) before gather\u001b[39;00m\n\u001b[1;32m    139\u001b[0m         dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m    140\u001b[0m         index\u001b[38;5;241m=\u001b[39my_out[:, :h]\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mexpand(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, R, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m),\n\u001b[1;32m    141\u001b[0m     )\u001b[38;5;241m.\u001b[39msum(\n\u001b[1;32m    142\u001b[0m         dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m\n\u001b[1;32m    143\u001b[0m     )  \u001b[38;5;66;03m# (B, R, 1)\u001b[39;00m\n\u001b[1;32m    144\u001b[0m     lsm_free \u001b[38;5;241m=\u001b[39m lsm_cp[:, :, h]  \u001b[38;5;66;03m# (B, R, V)\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# HPs\n",
    "num_epochs = 5\n",
    "lr = 0.001  \n",
    "\n",
    "model = MHEADS[\"moe_proj\"](\n",
    "    AbstractDisributionHeadConfig(\n",
    "        horizon=784,\n",
    "        d_model=10,  # 9 digits\n",
    "        d_output=2,  # 2 classes\n",
    "        rank=32,\n",
    "        pos_func='abs',\n",
    "    )\n",
    ")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "h=None\n",
    "for epoch in range(num_epochs):\n",
    "    pbar = tqdm(training_loader)\n",
    "    model.train()\n",
    "    for batch in pbar:\n",
    "        y, x = batch  # for gen modelling reverse x, y\n",
    "        B = x.shape[0]\n",
    "        z = (\n",
    "            torch.nn.functional.one_hot(\n",
    "                x,\n",
    "                num_classes=10,\n",
    "            )\n",
    "            .reshape(B, -1)\n",
    "            .to(torch.float32)\n",
    "        )  # (B, 10)\n",
    "        z, y = z.to(device), y.to(device)\n",
    "        output = model(z, y.reshape(B, -1))\n",
    "        loss = output.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        pbar.set_postfix(loss=loss.item())\n",
    "        # Sample\n",
    "        h = qual_eval(model, h, digit=0)   # reuse same output cell\n",
    "    print(f\"Epoch {epoch+1} | Loss: {loss.item()}\")\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3d53c5c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<DisplayHandle display_id=ad7f61317a3349a004928072b23f404b>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample\n",
    "qual_eval(model, h, digit=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
