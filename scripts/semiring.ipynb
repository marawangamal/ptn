{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89146b53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch-semiring-einsum in /Users/marawangamal/Documents/github/ptn/.venv/lib/python3.10/site-packages (1.2.0)\n",
      "Requirement already satisfied: pynvml<12.0.0,>=11.0.0 in /Users/marawangamal/Documents/github/ptn/.venv/lib/python3.10/site-packages (from torch-semiring-einsum) (11.5.3)\n",
      "Requirement already satisfied: torch<3,>=1.1.0 in /Users/marawangamal/Documents/github/ptn/.venv/lib/python3.10/site-packages (from torch-semiring-einsum) (2.8.0)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.0.0 in /Users/marawangamal/Documents/github/ptn/.venv/lib/python3.10/site-packages (from torch-semiring-einsum) (4.15.0)\n",
      "Requirement already satisfied: filelock in /Users/marawangamal/Documents/github/ptn/.venv/lib/python3.10/site-packages (from torch<3,>=1.1.0->torch-semiring-einsum) (3.19.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /Users/marawangamal/Documents/github/ptn/.venv/lib/python3.10/site-packages (from torch<3,>=1.1.0->torch-semiring-einsum) (1.14.0)\n",
      "Requirement already satisfied: networkx in /Users/marawangamal/Documents/github/ptn/.venv/lib/python3.10/site-packages (from torch<3,>=1.1.0->torch-semiring-einsum) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /Users/marawangamal/Documents/github/ptn/.venv/lib/python3.10/site-packages (from torch<3,>=1.1.0->torch-semiring-einsum) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /Users/marawangamal/Documents/github/ptn/.venv/lib/python3.10/site-packages (from torch<3,>=1.1.0->torch-semiring-einsum) (2025.9.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/marawangamal/Documents/github/ptn/.venv/lib/python3.10/site-packages (from sympy>=1.13.3->torch<3,>=1.1.0->torch-semiring-einsum) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/marawangamal/Documents/github/ptn/.venv/lib/python3.10/site-packages (from jinja2->torch<3,>=1.1.0->torch-semiring-einsum) (3.0.3)\n"
     ]
    }
   ],
   "source": [
    "# install einsum semirings\n",
    "!pip install torch-semiring-einsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad27807a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch_semiring_einsum\n",
    "\n",
    "# Log-space einsum, where addition replaced with LSE and\n",
    "# multiplication replaced with addition\n",
    "\n",
    "# Pre-compile an einsum equation.\n",
    "EQUATION = torch_semiring_einsum.compile_equation('bik,bkj->bij')\n",
    "# Create some parameters to multiply.\n",
    "A = torch.log(torch.rand(10, 3, 5, requires_grad=True))\n",
    "B = torch.log(torch.rand(10, 5, 7, requires_grad=True))\n",
    "# Run einsum.\n",
    "C = torch_semiring_einsum.log_einsum(EQUATION, A, B)\n",
    "# Now C is differentiable.\n",
    "C.sum().backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "51b4b769",
   "metadata": {},
   "outputs": [],
   "source": [
    "M, N, P = 10, 3, 8\n",
    "EQUATION_STR = 'mn,np->mp'\n",
    "EQUATION = torch_semiring_einsum.compile_equation(EQUATION_STR)\n",
    "logA, logB = torch.randn(M, N), torch.randn(N, P)\n",
    "res_1 = torch.einsum('mn,np->mp', A.exp(), B.exp()).log()\n",
    "res_2 = torch_semiring_einsum.log_einsum(EQUATION, A, B)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b20689ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.allclose(res_1, res_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8869a83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 8, 1, 1, 1, 1]) 256\n",
      "torch.Size([1, 1, 8, 8, 1, 1]) 256\n",
      "torch.Size([1, 1, 1, 1, 8, 8]) 256\n",
      "torch.Size([8, 8, 8, 8, 8, 8]) 256\n",
      "torch.Size([8, 8, 8, 8, 8, 8]) 256\n",
      "torch.Size([8, 8, 8, 8, 8, 8]) 256\n",
      "tens.shape torch.Size([3, 8, 8, 8, 8, 8, 8]) 3145728\n"
     ]
    }
   ],
   "source": [
    "R = 8\n",
    "A1 = torch.randn(R, R)\n",
    "A2 = torch.randn(R, R)\n",
    "A3 = torch.randn(R, R)\n",
    "\n",
    "# Make expanded tensors so Ak is 9-mode with same slice\n",
    "A1_lg = A1.reshape(R, R, *((1,1)*2))\n",
    "A2_lg = A2.reshape(*((1,1)*1), R, R, *((1,1)*1))\n",
    "A3_lg = A3.reshape(*((1,1)*2), R, R)\n",
    "\n",
    "# Before expand: just print actual storage mem\n",
    "for t in [A1_lg, A2_lg, A3_lg]:\n",
    "    print(f\"{t.shape} {t.untyped_storage().nbytes()}\")\n",
    "\n",
    "# Now expand \n",
    "A1_lg = A1_lg.expand(-1, -1, *((R, R)*2))\n",
    "A2_lg = A2_lg.expand(*((R, R)*1), -1, -1, *((R, R)*1))\n",
    "A3_lg = A3_lg.expand(*((R, R)*2), -1, -1)\n",
    "\n",
    "# After expand: just print actual storage mem\n",
    "for t in [A1_lg, A2_lg, A3_lg]:\n",
    "    print(f\"{t.shape} {t.untyped_storage().nbytes()}\")\n",
    "\n",
    "tens = torch.stack([A1_lg, A2_lg, A3_lg], dim=0)\n",
    "print(f\"tens.shape {tens.shape} {tens.untyped_storage().nbytes()}\") # <- blows up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a3e96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try lse on the flattened tensors\n",
    "\n",
    "lse = torch.logsumexp()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
